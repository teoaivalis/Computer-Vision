{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV-lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OT5qDkkLz4Un",
        "52iBFR2f8G2J",
        "YpK7sljt_L5T",
        "RXFM8VE9Ah-H",
        "oj-ZSrTJxHGu",
        "5duVLouO2mjV",
        "-YX4AOkY-wjd",
        "S9LPGgS-6uQB",
        "vcX2lDV5Wtob",
        "5prVKCU2Ympt",
        "Ef241QN79zYb",
        "iBVAZ0KZDJAm",
        "VgxBkCFdGD08",
        "xb672KvYaia6",
        "VpKmzFYFa8iY",
        "Gq_HVPlp89Yx",
        "6Qnj05pZ9KFM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFayqcyYL-Ij"
      },
      "source": [
        "Θεόδωρος Αϊβαλής, Α.Μ.: 03117099\n",
        "\n",
        "Θεοδότη Στόικου, Α.Μ.: 03117085\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT5qDkkLz4Un"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMr1ubfo0Ann"
      },
      "source": [
        "!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from scipy.ndimage import laplace\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        "import math\n",
        "from matplotlib.patches import Circle\n",
        "from math import ceil, floor\n",
        "\n",
        "print(cv2.__version__)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pztnybmzc56"
      },
      "source": [
        "#Μέρος 1: Ανίχνευση Ακμών σε Γκρίζες Εικόνες"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P866pNiQzi5d"
      },
      "source": [
        "##1.1. Δημιουργία Εικόνων Εισόδου"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHCdeNR5z3Zg"
      },
      "source": [
        "###1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSbKGb01yE88"
      },
      "source": [
        "img = cv2.imread('edgetest_10.png', cv2.IMREAD_GRAYSCALE)\n",
        "print(\"Resolution: \", img.shape)\n",
        "print(\"Range: %d - %d \" % (img.min(), img.max()))\n",
        "img = img.astype(np.float)/255\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFgU0yHz6i3E"
      },
      "source": [
        "###1.1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FioM2aFe8Eu1"
      },
      "source": [
        "####i) PSNR=20 dB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx9NWOUd5Hh6"
      },
      "source": [
        "mu, sigma1 = 0, 0.1 \n",
        "s1 = np.random.normal(mu, sigma1, (512, 512))\n",
        "s1= s1.reshape(512, 512)\n",
        "noisy1 = img + s1\n",
        "plt.imshow(noisy1, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52iBFR2f8G2J"
      },
      "source": [
        "####ii) PSNR=10 dB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhuyEpus6sAA"
      },
      "source": [
        "mu, sigma2 = 0, 0.316\n",
        "s2 = np.random.normal(mu, sigma2, (512, 512))\n",
        "s2= s2.reshape(512, 512)\n",
        "noisy2 = img + s2\n",
        "plt.imshow(noisy2, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRl8frtF9zwz"
      },
      "source": [
        "##1.2. Υλοποίηση Αλγορίθμων Ανίχνευσης Ακμών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF3wT2Ccw1-4"
      },
      "source": [
        "###1.2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpK7sljt_L5T"
      },
      "source": [
        "####i) Διδιάστατη Gaussian Gσ(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv5kSwgs_Ki0"
      },
      "source": [
        "def gaussianfil(image, sigma):\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  img_smooth = cv2.filter2D(image, -1, gauss2D)\n",
        "  print(gauss1D.shape, gauss1D.T.shape, gauss2D.shape)\n",
        "  plt.figure()\n",
        "  plt.imshow(img_smooth, cmap='gray')\n",
        "  plt.title(\"2D Gaussian\")\n",
        "  return img_smooth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWy1J-sU_3NU"
      },
      "source": [
        "res = gaussianfil(noisy1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFM8VE9Ah-H"
      },
      "source": [
        "####ii) Laplacian-of-Gaussian (LoG) h(x, y) = ∇2Gσ(x, y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI5xuUUL_8MD"
      },
      "source": [
        "def logfil(image, sigma):\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  ax = np.linspace(-(n - 1) / 2., (n - 1) / 2., n)\n",
        "  xx, yy = np.meshgrid(ax, ax)\n",
        "  kernel_log = (-1)/(np.pi*sigma**4)*(1-(xx**2+yy**2)/(2*sigma**2))*np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma))\n",
        "  img_smooth = cv2.filter2D(image, -1, kernel_log)\n",
        "  plt.figure()\n",
        "  plt.imshow(img_smooth, cmap='gray')\n",
        "  plt.title(\"Laplacian-of-Gaussian\") \n",
        "  return img_smooth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tq-XzA2FpbQ"
      },
      "source": [
        "res = logfil(noisy1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oilyi7ZrxCrp"
      },
      "source": [
        "###1.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj-ZSrTJxHGu"
      },
      "source": [
        "####i) Γραμμική (L1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx_mt7nFxOK3"
      },
      "source": [
        "def linearL(image, sigma):\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  L1= cv2.Laplacian(scipy.signal.convolve(gauss2D, image), cv2.CV_64F)\n",
        "  plt.figure()  \n",
        "  plt.imshow(L1, cmap='gray')\n",
        "  plt.title(\"Linear_Laplacian\")\n",
        "  return L1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI7Xpvhz1w0R"
      },
      "source": [
        "res = linearL(noisy1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5duVLouO2mjV"
      },
      "source": [
        "####ii) Μη-γραμμική (L2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-zytl732I0G"
      },
      "source": [
        "def nonlinearL(image, sigma):\n",
        "  B = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  Is = scipy.signal.convolve(gauss2D, image)\n",
        "  L2 = cv2.dilate(Is,B,iterations = 1) + cv2.erode(Is,B,iterations = 1) - 2*Is\n",
        "  plt.figure()\n",
        "  plt.imshow(L2, cmap = 'gray')\n",
        "  plt.title(\"Non_Linear_Laplacian\")\n",
        "  return L2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGByjb1n8AU3"
      },
      "source": [
        "res = nonlinearL(noisy1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YX4AOkY-wjd"
      },
      "source": [
        "###1.2.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiHRO9E894yt"
      },
      "source": [
        "def zerocrossingsL(image, sigma):\n",
        "  B = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
        "  L = logfil(image, sigma)\n",
        "  ret, X = cv2.threshold(L, 0, 1, cv2.THRESH_BINARY)\n",
        "  Y = cv2.dilate(X,B,iterations = 1) - cv2.erode(X,B,iterations = 1)\n",
        "  plt.figure()\n",
        "  plt.imshow(Y, cmap = 'gray_r')\n",
        "  plt.title(\"zeroCrossings\")\n",
        "  return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxT8-YG4BC_v"
      },
      "source": [
        "res = zerocrossingsL(noisy1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LPGgS-6uQB"
      },
      "source": [
        "###1.2.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYsJqWTwBNNn"
      },
      "source": [
        "def select_zcL(image, sigma, th):\n",
        "  Y = zerocrossingsL(image, sigma)\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  Is = scipy.signal.convolve(gauss2D, image)\n",
        "  gradimage = np.gradient(Is)\n",
        "  rows, columns = gradimage[0].shape\n",
        "  gradarray = np.zeros((rows, columns))\n",
        "  for i in range (rows):\n",
        "    for j in range (columns):\n",
        "      gradarray[i][j] = np.sqrt(gradimage[0][i][j]**2 + gradimage[1][i][j]**2)\n",
        "  limit = th * np.amax(gradarray)\n",
        "  (rowsY, columnsY) = Y.shape\n",
        "  for i in range (rowsY):\n",
        "    for j in range (columnsY):\n",
        "      if (Y[i][j] == 1):\n",
        "        if ((gradarray[i][j]) <= limit):\n",
        "          Y[i][j] = 0\n",
        "  plt.figure()  \n",
        "  plt.imshow(Y, cmap = 'gray_r')\n",
        "  plt.title(\"select_zeroCrossings\")\n",
        "  return Y  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ep2D3Yj-6uR"
      },
      "source": [
        "res =select_zcL(noisy1, 1, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzBji-NCA_1Z"
      },
      "source": [
        "def EdgeDetect(image, sigma, th, laplacian):\n",
        "  if (laplacian == 'linear'):\n",
        "    Is = linearL(image, sigma)\n",
        "  elif (laplacian == 'nonlinear'):\n",
        "    Is = nonlinearL(image, sigma)\n",
        "  Y = zerocrossingsL(image, sigma)\n",
        "  gradimage = np.gradient(Is)\n",
        "  rows, columns = gradimage[0].shape\n",
        "  gradarray = np.zeros((rows, columns))\n",
        "  for i in range (rows):\n",
        "    for j in range (columns):\n",
        "      gradarray[i][j] = np.sqrt(gradimage[0][i][j]**2 + gradimage[1][i][j]**2)\n",
        "  limit = th * np.amax(gradarray)\n",
        "  (rowsY, columnsY) = Y.shape\n",
        "  for i in range (rowsY):\n",
        "    for j in range (columnsY):\n",
        "      if (Y[i][j] == 1):\n",
        "        if ((gradarray[i][j]) <= limit):\n",
        "          Y[i][j] = 0\n",
        "  D = Y\n",
        "  plt.figure()\n",
        "  plt.imshow(D, cmap = 'gray_r')\n",
        "  plt.title(\"EdgeDetect\")\n",
        "  return D  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ORuG-W3Vk63"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1, 0.2, 'nonlinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6GCCjRsWD72"
      },
      "source": [
        "##1.3. Αξιολόγηση των Αποτελεσμάτων Ανίχνευσης Ακμών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcX2lDV5Wtob"
      },
      "source": [
        "###1.3.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4lihTLMWu1D"
      },
      "source": [
        "def real_edges(image, th_real):\n",
        "  B = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
        "  M = cv2.dilate(image,B,iterations = 1) - cv2.erode(image,B,iterations = 1)\n",
        "  ret, T = cv2.threshold(M, th_real, 1, cv2.THRESH_BINARY)\n",
        "  plt.figure()\n",
        "  plt.imshow(T, cmap='gray_r')\n",
        "  plt.title(\"real_edges\")  \n",
        "  return T;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTTMHhVYXrS"
      },
      "source": [
        "res = real_edges(img, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5prVKCU2Ympt"
      },
      "source": [
        "###1.3.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gce9q0o0YgZi"
      },
      "source": [
        "def evaluation(noisy_image, sigma, th, laplacian, image, th_real):\n",
        "  T_init = real_edges(image, th_real)\n",
        "  D_init = EdgeDetect(noisy_image, sigma, th, laplacian)\n",
        "  (rowsT, columnsT) = T_init.shape\n",
        "  (rowsD, columnsD) = D_init.shape\n",
        "  T = set()\n",
        "  D = set()\n",
        "  for i in range (rowsT):\n",
        "    for j in range (columnsT):\n",
        "      if (T_init[i][j]==1):\n",
        "        T.add((i,j))\n",
        "  for i in range (rowsD):\n",
        "    for j in range (columnsD):\n",
        "      if (D_init[i][j]==1):\n",
        "        D.add((i,j))\n",
        "  intersection = T.intersection(D)\n",
        "  precision = len(intersection) / len(D)\n",
        "  recall = len(intersection) / len(T)\n",
        "  C = (precision + recall) / 2\n",
        "  print(\"Precesion = \",precision)\n",
        "  print(\"Recall = \",recall)\n",
        "  print(\"C = \",C)\n",
        "  return C;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIOvIK6-p9g-"
      },
      "source": [
        "res = evaluation(noisy1, 2, 0.00001, 'nonlinear', img, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef241QN79zYb"
      },
      "source": [
        "###1.3.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBVAZ0KZDJAm"
      },
      "source": [
        "####Είσοδος με PSNR = 20 dB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLZq0jW-DVkh"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsQ0qU4KENKV"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfrhT1qLEXhc"
      },
      "source": [
        "res = EdgeDetect(noisy1, 2, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdk-mNmdEaLf"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.3, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HzRr7ntEfoU"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.17, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytLDwoe1Eh9H"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.2, 'nonlinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeJcq9dXEtvo"
      },
      "source": [
        "####Είσοδος με PSNR = 10 dB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p13DGs7Ewb9"
      },
      "source": [
        "res = EdgeDetect(noisy2, 3, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saFTEf09FlRv"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM2_FvZmFo2r"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1, 0.2, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_4zPzADFtOy"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.15, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGArOFZ6FyQa"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.25, 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyqyqorFF2g1"
      },
      "source": [
        "res = EdgeDetect(noisy1, 1.5, 0.2, 'nonlinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgxBkCFdGD08"
      },
      "source": [
        "##1.4. Εφαρμογή των Αλγορίθμων Ανίχνευσης Ακμών σε Πραγματικές εικόνες"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-MzVvemG3_G"
      },
      "source": [
        "###1.4.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN7zev7QG5Wl"
      },
      "source": [
        "img2 = cv2.imread('urban_edges.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "plt.figure()\n",
        "img2 = img2.astype(np.float)/255\n",
        "plt.figure()\n",
        "plt.imshow(img2, cmap='gray')\n",
        "plt.title(\"urban_edges\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ObZ07wVNrY"
      },
      "source": [
        "res = real_edges(img2, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PSnRtPQZqI0"
      },
      "source": [
        "def EdgeDetectColor(image, sigma, th):\n",
        "  Y = zerocrossingsL(image, sigma)\n",
        "  gradimage = np.gradient(image)\n",
        "  rows, columns = gradimage[0].shape\n",
        "  gradarray = np.zeros((rows, columns))\n",
        "  for i in range (rows):\n",
        "    for j in range (columns):\n",
        "      gradarray[i][j] = np.sqrt(gradimage[0][i][j]**2 + gradimage[1][i][j]**2)\n",
        "  limit = th * np.amax(gradarray)\n",
        "  (rowsY, columnsY) = Y.shape\n",
        "  for i in range (rowsY):\n",
        "    for j in range (columnsY):\n",
        "      if (Y[i][j] == 1):\n",
        "        if ((gradarray[i][j]) <= limit):\n",
        "          Y[i][j] = 0\n",
        "  D = Y\n",
        "  plt.figure()\n",
        "  plt.imshow(D, cmap = 'gray_r')\n",
        "  plt.title(\"EdgeDetect\")\n",
        "  return D  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9gCFLqDa04J"
      },
      "source": [
        "res = EdgeDetectColor(img2, 1, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saf3MPUWcphn"
      },
      "source": [
        "def evaluation_color(image, sigma, th, th_real):\n",
        "  T_init = real_edges(image, th_real)\n",
        "  D_init = EdgeDetectColor(image, sigma, th)\n",
        "  (rowsT, columnsT) = T_init.shape\n",
        "  (rowsD, columnsD) = D_init.shape\n",
        "  T = set()\n",
        "  D = set()\n",
        "  for i in range (rowsT):\n",
        "    for j in range (columnsT):\n",
        "      if (T_init[i][j]==1):\n",
        "        T.add((i,j))\n",
        "  for i in range (rowsD):\n",
        "    for j in range (columnsD):\n",
        "      if (D_init[i][j]==1):\n",
        "        D.add((i,j))\n",
        "  intersection = T.intersection(D)\n",
        "  precision = len(intersection) / len(D)\n",
        "  recall = len(intersection) / len(T)\n",
        "  C = (precision + recall) / 2\n",
        "  print(\"Precesion = \",precision)\n",
        "  print(\"Recall = \",recall)\n",
        "  print(\"C = \",C)\n",
        "  return C;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdVfC74Xc8xv"
      },
      "source": [
        "res = evaluation_color(img2, 1, 0.15, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4bqLklFbnsQ"
      },
      "source": [
        "###1.4.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-eCuBL9bqqT"
      },
      "source": [
        "res = EdgeDetectColor(img2, 1, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NenAa9vbxdJ"
      },
      "source": [
        "res = EdgeDetectColor(img2, 2, 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgRdTD0HcMhg"
      },
      "source": [
        "res = EdgeDetectColor(img2, 1, 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtWnBPITZymM"
      },
      "source": [
        "#Μέρος 2: Ανίχνευση Σημείων Ενδιαφέροντος (Interest Point Detection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxfrr7xVz2p"
      },
      "source": [
        "def interest_points_visualization(I_, kp_data_, ax=None):\n",
        "    '''\n",
        "    Plot keypoints chosen by detectos on image.\n",
        "    Args:\n",
        "        I_: Image (if colored, make sure it is in RGB and not BGR).\n",
        "        kp_data_: Nx3 array, as described in assignment.\n",
        "        ax: Matplotlib axis to plot on (if None, a new Axes object is created).\n",
        "    Returns:\n",
        "        ax: Matplotlib axis where the image was plotted.\n",
        "    '''\n",
        "    try:\n",
        "        I = np.array(I_)\n",
        "        kp_data = np.array(kp_data_)\n",
        "    except:\n",
        "        print('Conversion to numpy arrays failed, check if the inputs (image and keypoints) are in the required format.')\n",
        "        exit(2)\n",
        "\n",
        "    try:\n",
        "        assert(len(I.shape) == 2 or (len(I.shape) == 3 and I.shape[2] == 3))\n",
        "    except AssertionError as e:\n",
        "        print('interest_points_visualization: Image must be either a 2D matrix or a 3D matrix with the last dimension having size equal to 3.', file=sys.stderr)\n",
        "        exit(2)\n",
        "\n",
        "    try:\n",
        "        assert(len(kp_data.shape) == 2 and kp_data.shape[1] == 3)\n",
        "    except AssertionError as e:\n",
        "        print('interest_points_visualization: kp_data must be a 2D matrix with 3 columns.', file=sys.stderr)\n",
        "        exit(2)\n",
        "\n",
        "    if ax is None:\n",
        "        _, ax = plt.subplots()\n",
        "\n",
        "    ax.set_aspect('equal')\n",
        "    ax.imshow(I)\n",
        "    ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
        "\n",
        "    for i in range(len(kp_data)):\n",
        "        x, y, sigma = kp_data[i]\n",
        "        circ = Circle((x, y), 3*sigma, edgecolor='g', fill=False, linewidth=2)\n",
        "        ax.add_patch(circ)\n",
        "\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NEqsSQ6YIS1"
      },
      "source": [
        "img3 = cv2.imread('mars.png')\n",
        "plt.figure()\n",
        "plt.imshow(img3)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
        "plt.figure()\n",
        "plt.imshow(img3)\n",
        "img3_gray = cv2.cvtColor(img3, cv2.COLOR_RGB2GRAY)\n",
        "img3_gray = img3_gray.astype(np.float)/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_hQT9sOZk5A"
      },
      "source": [
        "img4 = cv2.imread('blood_smear.jpg')\n",
        "plt.figure()\n",
        "plt.imshow(img4)\n",
        "img4 = cv2.cvtColor(img4, cv2.COLOR_BGR2RGB)\n",
        "plt.figure()\n",
        "plt.imshow(img4)\n",
        "img4_gray = cv2.cvtColor(img4, cv2.COLOR_RGB2GRAY)\n",
        "img4_gray = img4_gray.astype(np.float)/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27n7Xd9_Zz2s"
      },
      "source": [
        "##2.1. Ανίχνευση Γωνιών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb672KvYaia6"
      },
      "source": [
        "###2.1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CwROhfucyrZ"
      },
      "source": [
        "def find_J(image, sigma, r):\n",
        "  n1 = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n1, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  Is = cv2.filter2D(image, -1, gauss2D)\n",
        "  n2 = int(2*np.ceil(3*r)+1)\n",
        "  gauss1Dr = cv2.getGaussianKernel(n2, r) # Column vector\n",
        "  gauss2Dr = gauss1Dr @ gauss1Dr.T # Symmetric gaussian kernel\n",
        "  der_x = cv2.Sobel(Is,cv2.CV_64F,1,0)\n",
        "  der_y = cv2.Sobel(Is,cv2.CV_64F,0,1)\n",
        "  mul1 = np.multiply(der_x, der_x)\n",
        "  mul2 = np.multiply(der_x, der_y)\n",
        "  mul3 = np.multiply(der_y, der_y)\n",
        "  J1 = cv2.filter2D(mul1, -1, gauss2Dr)\n",
        "  plt.figure()\n",
        "  plt.imshow(J1, cmap = 'gray_r')\n",
        "  J2 = cv2.filter2D(mul2, -1, gauss2Dr)\n",
        "  plt.figure()\n",
        "  plt.imshow(J2, cmap = 'gray_r')\n",
        "  J3 = cv2.filter2D(mul3, -1, gauss2Dr)\n",
        "  plt.figure()\n",
        "  plt.imshow(J3, cmap = 'gray_r')\n",
        "  return (J1, J2, J3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDEYJUuUipf"
      },
      "source": [
        "(J1, J2, J3) = find_J(img2, 2, 2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "263wZUTbXMdQ"
      },
      "source": [
        "find_J(img3_gray, 2, 2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdkTZQuDaypg"
      },
      "source": [
        "find_J(img4_gray, 2, 2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpKmzFYFa8iY"
      },
      "source": [
        "###2.1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8YnHdJpfoLA"
      },
      "source": [
        "def eigenvalues(image, sigma, r):\n",
        "  (J1, J2, J3) = find_J(image, sigma, r)\n",
        "  l_plus = 0.5 * (J1 + J3 + np.sqrt(np.multiply(J1-J3, J1-J3) + 4*np.multiply(J2, J2)))\n",
        "  plt.figure()\n",
        "  plt.imshow(l_plus, cmap = 'gray_r')\n",
        "  l_minus = 0.5 * (J1 + J3 - np.sqrt(np.multiply(J1-J3, J1-J3) + 4*np.multiply(J2, J2)))\n",
        "  plt.figure()\n",
        "  plt.imshow(l_minus, cmap = 'gray_r')\n",
        "  return(l_plus, l_minus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEX1-Vxmg0Yj"
      },
      "source": [
        "(l_plus, l_minus) = eigenvalues(img2, 2, 2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esDc7ssXm5wc"
      },
      "source": [
        "###2.1.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQwlakRUm-Bm"
      },
      "source": [
        "def find_R(image, sigma, r, k):\n",
        "  (l_plus, l_minus) = eigenvalues(image, sigma, r)\n",
        "  R = np.multiply(l_plus, l_minus) - k * np.multiply(l_plus + l_minus, l_plus + l_minus)\n",
        "  plt.figure()\n",
        "  plt.imshow(R, cmap = 'gray_r')\n",
        "  return R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7y8uc-xuQf_"
      },
      "source": [
        "def disk_strel(n):\n",
        "    '''\n",
        "        Return a structural element, which is a disk of radius n.\n",
        "    '''\n",
        "    r = int(np.round(n))\n",
        "    d = 2*r+1\n",
        "    x = np.arange(d) - r\n",
        "    y = np.arange(d) - r\n",
        "    x, y = np.meshgrid(x,y)\n",
        "    strel = x**2 + y**2 <= r**2\n",
        "    return strel.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpiN40_0r5t-"
      },
      "source": [
        "def choose_corners(image, sigma, r, k, th_corn):\n",
        "  R = find_R(image, sigma, r, k)\n",
        "  ns = np.ceil(3*sigma)*2+1\n",
        "  B_sq = disk_strel(ns)\n",
        "  Cond1 = ( R==cv2.dilate(R,B_sq) )\n",
        "  Cond2 = ( R > th_corn * np.amax(R) )\n",
        "  Cond_total = (Cond1 & Cond2)\n",
        "  result = np.where(Cond_total == True)\n",
        "  listOfCoordinates= list(zip(result[0], result[1]))\n",
        "  arr = []\n",
        "  for coordinate in listOfCoordinates:\n",
        "   arr.append([coordinate[1], coordinate[0], sigma])\n",
        "  return np.array(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oCuXqUSvUEr"
      },
      "source": [
        "arr = choose_corners(img2, 1.5, 2.5, 0.05, 0.005)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"urban_edges.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20OyaXTAT197"
      },
      "source": [
        "arr = choose_corners(img3_gray, 1.5, 2.5, 0.05, 0.005)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"mars.png\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFYX7VvyT3s1"
      },
      "source": [
        "arr = choose_corners(img4_gray, 1.5, 2.5, 0.05, 0.005)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"blood_smear.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAkdiGhrSCeA"
      },
      "source": [
        "##2.2. Πολυκλιμακωτή Ανίχνευση Γωνιών\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCjWVyIoTdBx"
      },
      "source": [
        "###2.2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gb4B-yNTeXA"
      },
      "source": [
        "def multiscale_choose_corners (image, sigma, r, k, th_corn, N, s):\n",
        "  sigma_new = sigma * pow(s, N)\n",
        "  r_new = r * pow(s, N)\n",
        "  result = choose_corners(image, sigma_new, r_new, k, th_corn)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzyGOAnxXu3l"
      },
      "source": [
        "res = multiscale_choose_corners (img2, 2, 2.5, 0.05, 0.005, 1, 1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBtuD_npXwtE"
      },
      "source": [
        "###2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4wwpz3OXyO6"
      },
      "source": [
        "def criterion(image, sigma, r, k, th_corn, N, s):\n",
        "  sigma_new = sigma * pow(s, N)\n",
        "  r_new = r * pow(s, N)\n",
        "  normalized_log = pow(sigma_new, 2) * np.absolute(logfil(image, sigma_new))\n",
        "  plt.imshow(normalized_log, cmap='gray')\n",
        "  return normalized_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twdCABuc1yT2"
      },
      "source": [
        "def Gauss(img,sigma):\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gauss1D = cv2.getGaussianKernel(n, sigma) # Column vector\n",
        "  gauss2D = gauss1D @ gauss1D.T # Symmetric gaussian kernel\n",
        "  gaussian = cv2.filter2D(img, 6, gauss2D)\n",
        "  return gaussian/gaussian.max()\n",
        "  \n",
        "\n",
        "def LoG(img,sigma):\n",
        "  n = int(2*np.ceil(3*sigma)+1)\n",
        "  gaussfiltered  = Gauss(img,sigma)\n",
        "  laplacian = cv2.Laplacian(gaussfiltered, -1, ksize=n)\n",
        "  return laplacian/laplacian.max()\n",
        "\n",
        "def LoG_arr(img,sigma0, scale, N):\n",
        "\tabs_log_array = [0]*N\n",
        "\tfor i in range(0, N):\n",
        "\t\tsigma = sigma0*scale**i\n",
        "\t\tn = int(2*np.ceil(3*sigma)+1)\n",
        "\t\tgaussfiltered  = Gauss(img,sigma)\n",
        "\t\tabs_log_array[i] = sigma*sigma*np.abs(cv2.Laplacian(gaussfiltered, cv2.CV_64F ))\n",
        "\treturn abs_log_array\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjH35jKK09lt"
      },
      "source": [
        "def multiscale_corner_detection(image, sigma0, r, k, theta_corn, N, scale):\n",
        "\t\n",
        "\tif isinstance(image, str):\n",
        "\t\tgray = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
        "\telse:\n",
        "\t\tgray = image\n",
        "\tabs_lap_o_gaus = LoG_arr(gray, sigma0, scale, N)\n",
        "\tarr = []\n",
        "\n",
        "\tfor i in range(0,N):\n",
        "\n",
        "\n",
        "\t\t########################2.2.1########################\n",
        "\t\tsigma = sigma0*scale**i\n",
        "\t\tns = (ceil(3*sigma))*2 + 1\n",
        "\t\tnr = (ceil(3*r))*2 + 1\n",
        "\t\tGs = cv2.getGaussianKernel(ns, sigma)\n",
        "\t\tGr = cv2.getGaussianKernel(nr, r)\n",
        "\t\tIs = cv2.filter2D(gray, -1,  Gs)\n",
        "\t\t[dx,dy] = np.gradient(Is)\n",
        "\t\tJ1 = cv2.filter2D(np.multiply(dx,dx), -1,  Gr)\n",
        "\t\tJ2 = cv2.filter2D(np.multiply(dx,dy), -1,  Gr)\n",
        "\t\tJ3 = cv2.filter2D(np.multiply(dy,dy), -1,  Gr)\n",
        "\n",
        "\t\tJ1_J3squared = (J1-J3)*(J1-J3)\n",
        "\t\tJ2_squared = 4*np.square(J2)\n",
        "\t\tl_pos = 0.5*(J1+J3+np.sqrt(J1_J3squared+J2_squared))\n",
        "\t\tl_neg = 0.5*(J1+J3-np.sqrt(J1_J3squared+J2_squared))\n",
        "\n",
        "\n",
        "\t\tR = l_neg*l_pos - k*(np.square(l_neg+l_pos))\n",
        "\t\tR_max = np.amax(R)\n",
        "\t\tB_sq = disk_strel(ns)\n",
        "\t\tCond1 = ( R==cv2.dilate(R,B_sq) )\n",
        "\t\tCond2 = R > theta_corn*R_max\n",
        "\t\tif i == 0:\n",
        "\t\t\tAbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  )\n",
        "\t\telif i == N-1:\n",
        "\t\t\tAbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )\n",
        "\t\telse:\n",
        "\t\t\tAbsLogCond = np.logical_and( (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  ), (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )  )\n",
        "\t\tcond = np.logical_and(np.logical_and(Cond1, Cond2), AbsLogCond)\n",
        "\t\tresult = np.where(cond == True)\n",
        "\t\tlistOfCoordinates= list(zip(result[0], result[1]))\n",
        "\t\n",
        "\t\tfor coordinate in listOfCoordinates:\n",
        "\t\t\tarr.append([coordinate[1], coordinate[0], sigma])\n",
        "\treturn np.array(arr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv6RAg3a1Drt"
      },
      "source": [
        "arr = multiscale_corner_detection(img4_gray, 3, 2.5, 0.05, 0.005, 5, 1.5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"blood_smear.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnKpVvAwWRqv"
      },
      "source": [
        "arr = multiscale_corner_detection(img3_gray, 3, 2.5, 0.05, 0.005, 5, 1.5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"mars.png\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWAHpYVQPL1D"
      },
      "source": [
        "##2.3. Ανίχνευση Blobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66fTveMdPPu6"
      },
      "source": [
        "def blob_detection(image, sigma, threshold):\n",
        "\n",
        "\t########################2.3.1########################\n",
        "\tif isinstance(image, str):\n",
        "\t\tgray = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
        "\telse:\n",
        "\t\tgray = image\n",
        "\tns = (ceil(3*sigma))*2 + 1\n",
        "\tGs = cv2.getGaussianKernel(ns, sigma)\n",
        "\tIs = cv2.filter2D(gray, -1,  Gs)\n",
        "\t[gx,gy] = np.gradient(Is)\n",
        "\t[hxx,hxy] = np.gradient(gx)\n",
        "\t[hyx,hyy] = np.gradient(gy)\n",
        "\t\n",
        "\tR = hxx*hyy - hxy*hxy\n",
        "\n",
        "\t# cv2.imshow(\"R\", R)\n",
        "\t# cv2.waitKey()\n",
        "\n",
        "\t########################2.3.2########################\n",
        "\tR_max = R.max()\n",
        "\tB_sq = disk_strel(ns)\n",
        "\tCond1 = (R == cv2.dilate(R,B_sq))\n",
        "\tCond2 = (R > threshold*R_max)\n",
        "\tcond = Cond1&Cond2\n",
        "\tresult = np.where(cond == True)\n",
        "\tlistOfCoordinates= list(zip(result[0], result[1]))\n",
        "\tarr = []\n",
        "\tfor coordinate in listOfCoordinates:\n",
        "\t\tarr.append([coordinate[1], coordinate[0], sigma])\n",
        "\treturn np.array(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORAhy3M6ehHR"
      },
      "source": [
        "arr = blob_detection(img3_gray, 1, 0.05)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"mars.png\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_JUWOn2YGJK"
      },
      "source": [
        "arr = blob_detection(img4_gray, 1, 0.05)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"blood_smear.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UsrudX0e_ZF"
      },
      "source": [
        "##2.4. Πολυκλιμακωτή Ανίχνευση Blobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mReOb5cfBnv"
      },
      "source": [
        "###2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZTsjBmq5gBZ"
      },
      "source": [
        "def multiscale_blob_detection(image, sigma0, threshold, scale, N):\n",
        "\n",
        "    ########################2.4.1########################\n",
        "    if isinstance(image, str):\n",
        "        gray = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
        "    else:\n",
        "        gray = image\n",
        "    abs_lap_o_gaus = LoG_arr(gray, sigma0, scale, N)\n",
        "    arr = []\n",
        "\n",
        "\n",
        "    for i in range(0,N):\n",
        "        sigma = sigma0*scale**i\n",
        "        ns = (ceil(3*sigma))*2 + 1\n",
        "        Gs = cv2.getGaussianKernel(ns, sigma)\n",
        "        Is = cv2.filter2D(gray, -1,  Gs)\n",
        "        Gs = cv2.getGaussianKernel(ns, sigma)\n",
        "        Is = cv2.filter2D(gray, -1,  Gs)\n",
        "        [gx,gy] = np.gradient(Is)\n",
        "        [hxx,hxy] = np.gradient(gx)\n",
        "        [hyx,hyy] = np.gradient(gy)\n",
        "        \n",
        "        R = hxx*hyy - hxy*hxy\n",
        "        \n",
        "        if i == 0:\n",
        "            AbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  )\n",
        "        elif i == N-1:\n",
        "            AbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )\n",
        "        else:\n",
        "            AbsLogCond = np.logical_and( (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  ), (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )  )\n",
        "\n",
        "        R_max = R.max()\n",
        "        B_sq = disk_strel(ns)\n",
        "        Cond1 = (R == cv2.dilate(R,B_sq))\n",
        "        Cond2 = (R >= threshold*R_max)\n",
        "        cond = Cond1&Cond2&AbsLogCond\n",
        "        result = np.where(cond == True)\n",
        "        listOfCoordinates= list(zip(result[0], result[1]))\n",
        "    \n",
        "        for coordinate in listOfCoordinates:\n",
        "            arr.append([coordinate[1], coordinate[0], sigma])\n",
        "    return np.array(arr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhX7Scvp58SO"
      },
      "source": [
        "arr = multiscale_blob_detection(img3_gray, 2.5, 0.1, 1.5, 5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"mars.png\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt_66tR-Wucg"
      },
      "source": [
        "arr = multiscale_blob_detection(img4_gray, 2.5, 0.1, 1.5, 5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"blood_smear.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf5w9B-KLW3i"
      },
      "source": [
        "##2.5. Επιτάχυνση με την χρήση Box Filters και Ολοκληρωτικών Εικόνων (Integral Images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob2LjSHDLzJz"
      },
      "source": [
        "def integral_image(image):\n",
        "  S = np.cumsum(np.cumsum(image, axis=0), axis=1)\n",
        "  plt.imshow(S)\n",
        "  return S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD5meTlXQvAS"
      },
      "source": [
        "integral_image(img3_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2BRUlriSWuF"
      },
      "source": [
        "def compute_integral(integral, shiftX, shiftY, offsetx, offsety):\n",
        "    shiftX = -int(shiftX)\n",
        "    shiftY = -int(shiftY)\n",
        "    offsetx = -int(offsetx)\n",
        "    offsety = -int(offsety)\n",
        "\n",
        "    # Right-Bottom corner\n",
        "    sD = np.roll(integral,-1*shiftY + offsety,axis = 0)\n",
        "    sD = np.roll(sD,-1*shiftX + offsetx, axis = 1)\n",
        "    # Left-Top Corner\n",
        "    sA = np.roll(integral,shiftY + offsety,axis = 0)\n",
        "    sA = np.roll(sA,shiftX + offsetx,axis = 1)\n",
        "    # Right-Top corner\n",
        "    sB = np.roll(integral,shiftY + offsety,axis = 0)\n",
        "    sB = np.roll(sB,-1*shiftX + offsetx,axis = 1)\n",
        "    # Left-Bottom Corner\n",
        "    sC = np.roll(integral,-1*shiftY + offsety,axis = 0)\n",
        "    sC = np.roll(sC,shiftX + offsetx,axis = 1)\n",
        "    return [sA,sB,sC,sD]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxqzlFmTTlPT"
      },
      "source": [
        "def padarray(array, offset):\n",
        "    return np.pad(array, offset, 'constant', constant_values=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4xwHE6LTnww"
      },
      "source": [
        "def unpad(array, offset):\n",
        "    return array[offset:-offset, offset:-offset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GIdD91FTx2e"
      },
      "source": [
        "def boxfilters(image, sigma, threshold, scale, N, multi = False):\n",
        "    ########################2.5.2########################\n",
        "    if isinstance(image, str):\n",
        "        gray = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
        "    else:\n",
        "        gray = image    \n",
        "    n = 2*ceil(3*sigma) + 1\n",
        "\n",
        "    Ipadded = padarray(gray,floor(n/2))\n",
        "    integral = integral_image(Ipadded)\n",
        " \n",
        "    xDxx = 2*floor(n/6) + 1\n",
        "    yDxx = 4*floor(n/6) + 1\n",
        "    xDyy = 4*floor(n/6) + 1\n",
        "    yDyy = 2*floor(n/6) + 1\n",
        "    xDxy = 2*floor(n/6) + 1\n",
        "    yDxy = 2*floor(n/6) + 1\n",
        "\n",
        "    ######################## Lxx ########################\n",
        "    # Central Box\n",
        "    magnitude = -2\n",
        "    shiftX = (xDxx -1)/2\n",
        "    shiftY = (yDxx -1)/2\n",
        "    pad = floor(n/2) \n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, 0, 0 )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxx = magnitude*(sD + sA - sB - sC) \n",
        "\n",
        "    # Left and Right Box\n",
        "    magnitude = 1\n",
        "    shiftX = (xDxx -1)/2 + xDxx\n",
        "    shiftY = (yDxx -1)/2\n",
        "    pad = floor(n/2) \n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, 0, 0 )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxx = magnitude*(sD + sA - sB - sC) + Lxx\n",
        "\n",
        "    ######################## Lyy ########################\n",
        "    # Central Box\n",
        "    magnitute = -2\n",
        "    shiftX = (xDyy -1)/2\n",
        "    shiftY = (yDyy -1)/2\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY ,0, 0)\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lyy = magnitude*(sD + sA - sB - sC)\n",
        "\n",
        "    # Top and Bottom Box\n",
        "    magnitude = 1\n",
        "    shiftX = (xDyy -1)/2\n",
        "    shiftY = (yDyy -1)/2 + yDyy\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY , 0 , 0)\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lyy = magnitude*(sD + sA - sB - sC) + Lyy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ######################## Lxy ########################\n",
        "    # Θεωρούμε πως η ενδιάμεση λωρίδα απο pixels ανάμεσα στα παράθυρα έχει\n",
        "    # πάχος 1\n",
        "    if( ceil((n-2*xDxy)/3)%2 == 1):\n",
        "        rDxy = ceil((n-2*xDxy)/3)\n",
        "    else:\n",
        "        rDxy = floor((n-2*xDxy)/3)\n",
        "\n",
        "\n",
        "    # Top Right Box\n",
        "    magnitute = -1\n",
        "    offsetx = -1*(rDxy-1)/2 - (xDxy -1)/2\n",
        "    offsety = (rDxy-1)/2 + (yDxy -1)/2\n",
        "    shiftX = (xDxy -1)/2\n",
        "    shiftY = (yDxy -1)/2\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, offsetx, offsety )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxy = magnitude*(sD + sA - sB - sC)\n",
        "\n",
        "    # Top Left Box\n",
        "    magnitute = 1\n",
        "    offsetx = (rDxy-1)/2 + (xDxy -1)/2\n",
        "    offsety = (rDxy-1)/2 + (yDxy -1)/2\n",
        "    shiftX = (xDxy -1)/2\n",
        "    shiftY = (yDxy -1)/2\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, offsetx, offsety  )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxy = magnitude*(sD + sA - sB - sC) + Lxy\n",
        "\n",
        "    # Bottom Left Box\n",
        "    magnitute = -1\n",
        "    offsetx = (rDxy-1)/2 + (xDxy -1)/2\n",
        "    offsety = -1*(rDxy-1)/2 - (yDxy -1)/2\n",
        "    shiftX = (xDxy -1)/2\n",
        "    shiftY = (yDxy -1)/2\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, offsetx, offsety  )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxy = magnitude*(sD + sA - sB - sC) + Lxy\n",
        "\n",
        "    # Bottom Right Box\n",
        "    magnitute = 1\n",
        "    offsetx = -1*(rDxy-1)/2 - (xDxy -1)/2\n",
        "    offsety = -1*(rDxy-1)/2 - (yDxy -1)/2\n",
        "    shiftX = (xDxy -1)/2\n",
        "    shiftY = (yDxy -1)/2\n",
        "    [ tsA,tsB,tsC,tsD ] = compute_integral( integral, shiftX, shiftY, offsetx, offsety  )\n",
        "    sA = unpad(tsA,pad)\n",
        "    sB = unpad(tsB,pad)\n",
        "    sC = unpad(tsC,pad)\n",
        "    sD = unpad(tsD,pad)\n",
        "\n",
        "    Lxy = magnitude*(sD + sA - sB - sC) + Lxy\n",
        "    ########################2.5.3########################\n",
        "    R = Lxx*Lyy - (0.9*Lxy)**2\n",
        "    R_max = R.max()\n",
        "    B_sq = disk_strel(n)\n",
        "    Cond1 = (R == cv2.dilate(R,B_sq))\n",
        "    Cond2 = (R > threshold*R_max)\n",
        "    cond = Cond1&Cond2\n",
        "    result = np.where(cond == True)\n",
        "    listOfCoordinates= list(zip(result[0], result[1]))\n",
        "    if multi:\n",
        "        return cond\n",
        "    arr = []\n",
        "    for coordinate in listOfCoordinates:\n",
        "        arr.append([coordinate[1], coordinate[0], sigma])\n",
        "\n",
        "    return np.array(arr)\n",
        "\n",
        "#    print(Lxx)\n",
        "#   print(Lyy)\n",
        "#    print(Lxy)\n",
        "#    plt.figure()\n",
        "#    plt.imshow(Lxx)\n",
        "#    plt.title('Lxx')\n",
        "#    plt.figure()\n",
        "#    plt.imshow(Lyy)\n",
        "#    plt.title('Lyy')\n",
        "#    plt.figure()\n",
        "#    plt.imshow(Lxy)\n",
        "#    plt.title('Lxy')\n",
        "\n",
        "#    return(Lxx, Lyy, Lxy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIXFS8C27e9_"
      },
      "source": [
        "def multiscale_boxfilters(image, sigma0, threshold, scale, N):\n",
        "\t########################2.5.4########################\n",
        "\tif isinstance(image, str):\n",
        "\t\tgray = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
        "\telse:\n",
        "\t\tgray = image\n",
        "\tabs_lap_o_gaus = LoG_arr(gray, sigma0, scale, N)\n",
        "\tarr = []\n",
        "\n",
        "\tfor i in range(0,N):\n",
        "\t\tsigma = sigma0*scale**i\n",
        "\t\tinterestmap = boxfilters(image, sigma, threshold, scale, 1, multi=True)\n",
        "\n",
        "\t\tif i == 0:\n",
        "\t\t\tAbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  )\n",
        "\t\telif i == N-1:\n",
        "\t\t\tAbsLogCond = (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )\n",
        "\t\telse:\n",
        "\t\t\tAbsLogCond = np.logical_and( (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i+1]  ), (  abs_lap_o_gaus[i] >= abs_lap_o_gaus[i-1]  )  )\n",
        "\t\tcond = interestmap&AbsLogCond\n",
        "\t\tresult = np.where(cond == True)\n",
        "\t\tlistOfCoordinates= list(zip(result[0], result[1]))\n",
        "\t\n",
        "\t\tfor coordinate in listOfCoordinates:\n",
        "\t\t\tarr.append([coordinate[1], coordinate[0], sigma])\n",
        "\treturn np.array(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17vkze217mmz"
      },
      "source": [
        "arr = multiscale_boxfilters(img4_gray, 2.5, 0.01, 1.5, 5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"blood_smear.jpg\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymC7OOIyZa1a"
      },
      "source": [
        "arr = multiscale_boxfilters(img3_gray, 2.5, 0.01, 1.5, 5)\n",
        "ax = interest_points_visualization(cv2.cvtColor(cv2.imread(\"mars.png\"), cv2.COLOR_BGR2RGB), arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qnj05pZ9KFM"
      },
      "source": [
        "#Μέρος 3: Εφαρμογές σε Ταίριασμα και Κατηγοριοποίηση Εικόνων με Χρήση Τοπικών Περιγραφητών στα Σημεία Ενδιαφέροντος"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV5t8A7dAvFb"
      },
      "source": [
        "import cv21_lab1_part3_utils as p3\n",
        "#import cv21_lab1_part2_utils as p2\n",
        "\n",
        "#from cv21_lab1_part3_utils import featuresSURF\n",
        "#from cv21_lab1_part3_utils import featuresHOG\n",
        "from cv21_lab1_part3_utils import matching_evaluation\n",
        "#from cv21_lab1_part3_utils import createTrainTest\n",
        "#from cv21_lab1_part3_utils import BagOfWords\n",
        "#from cv21_lab1_part3_utils import svm\n",
        "#from cv21_lab1_part3_utils import FeatureExtraction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHOarhWBf9pn"
      },
      "source": [
        "p3.matching_evaluation?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FguVV4HK9fKW"
      },
      "source": [
        "##3.1. Ταίριασμα Εικόνων υπό Περιστροφή και Αλλαγή Κλίμακας"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjzJiEGD8Oc9"
      },
      "source": [
        "!unzip cv21_lab1_part3_material.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHhZglWnOEph"
      },
      "source": [
        "!mv glove.* cv21_lab1_part3_material -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4cikFmSEfXq"
      },
      "source": [
        "detect_fun = lambda I: choose_corners(I, 3, 2.5, 0.05, 0.005)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))\n",
        "\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0I7JaaPEyXS"
      },
      "source": [
        "detect_fun = lambda I: multiscale_corner_detection(I, 3, 2.5, 0.05, 0.005,4,1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))\n",
        "\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAZdXAKBE1AU"
      },
      "source": [
        "detect_fun = lambda I: choose_blobs(I, 3, 0.12)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))\n",
        "\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atAh3idEE12V"
      },
      "source": [
        "detect_fun = lambda I: merged_choice_blobs(I, 3, 0.12, 6, 1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))\n",
        "\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3iDgkViE77m"
      },
      "source": [
        "detect_fun = lambda I: merged_choice_points_of_interest(I, 2.5, 0.05, 4, 1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i]))\n",
        "\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun, desc_fun)\n",
        "print(avg_scale_errors)\n",
        "print(avg_theta_errors)\n",
        "\n",
        "for i in range(3):\n",
        "    print('Avg. Scale Error for Image {:.3f}: {:.3f}'.format(i,avg_scale_errors[i]))\n",
        "    print('Avg. Theta Error for Image {:.3f}: {:.3f}'.format(i,avg_theta_errors[i])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOnYdnxkYSGG"
      },
      "source": [
        "##3.2. Κατηγοριοποίηση Εικόνων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dObFSJkcY2Yr"
      },
      "source": [
        "###3.2.1, 3.2.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiXsMM2eY5b8"
      },
      "source": [
        "detect_fun = lambda I: merged_choice(I, 3, 2.5, 0.05, 0.005,4,1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "val1 = p3.FeatureExtraction(detect_fun, desc_fun)\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "val2 = p3.FeatureExtraction(detect_fun, desc_fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJx_H1lcZT4h"
      },
      "source": [
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val1, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "print(accs)\n",
        "print('Mean accuracy for Harris-Laplace with SURF descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val2, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "\n",
        "print('Mean accuracy for Harris-Laplace with HOG descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "print(accs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaDmOT1sZWNu"
      },
      "source": [
        "detect_fun = lambda I:  merged_choice_blobs(I, 3, 0.12, 6, 1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "val3 = p3.FeatureExtraction(detect_fun, desc_fun)\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "val4 = p3.FeatureExtraction(detect_fun, desc_fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y3KyRGqZZJX"
      },
      "source": [
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val3, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "print(accs)\n",
        "\n",
        "print('Mean accuracy for Blob Detection with SURF descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val4, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "\n",
        "print('Mean accuracy for Blob Detection with HOG descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "print(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRt2akKVZaB8"
      },
      "source": [
        "detect_fun = lambda I: merged_choice_points_of_interest(I, 2.5, 0.05, 4, 1.5)\n",
        "\n",
        "print(\"########## SURF ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresSURF(I, kp)\n",
        "val5 = p3.FeatureExtraction(detect_fun, desc_fun)\n",
        "    \n",
        "print(\"########## HOG ##########\")\n",
        "desc_fun = lambda I, kp: p3.featuresHOG(I, kp)\n",
        "val6 = p3.FeatureExtraction(detect_fun, desc_fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08QreAuQZe0Z"
      },
      "source": [
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val5, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "print(accs)\n",
        "\n",
        "print('Mean accuracy for Box Filters with SURF descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "\n",
        "\n",
        "accs = []\n",
        "for k in range(5):\n",
        "    # Split into a training set and a test set.\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val6, k)\n",
        "\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
        "\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    accs.append(acc)\n",
        "\n",
        "print('Mean accuracy for Box Filters with HOG descriptors: {:.3f}%'.format(100.0*np.mean(accs)))\n",
        "print(accs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o4n-Sykb64L"
      },
      "source": [
        "###3.2.3, 3.2.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s0mZ9a1b8H_"
      },
      "source": [
        "def BoVW_hist(features, centers, kmeans):\n",
        "    distances = np.zeros((features.shape[0], centers.shape[0]))\n",
        "    for  descriptor in range(0, features.shape[0]):\n",
        "        for center in range(0, centers.shape[0]):\n",
        "            sum = 0\n",
        "            for i in range(0, features[descriptor].shape[0]):\n",
        "                 sum += (features[descriptor][i] - centers[center][i])**2\n",
        "            distances[descriptor][center] = sqrt(sum)\n",
        "    mins = np.min(distances, axis = 1)   \n",
        "#     Distances = kmeans.transform(features)\n",
        "#     #print(Distances.shape)\n",
        "#     #minx, miny = list(zip( np.where(Distance == np.amin(Distance))[0],np.where(Distance == np.amin(Distance))[1] ))[0]\n",
        "#     mins = np.min(Distances, axis=1) \n",
        "    hist, bin_edges = np.histogram(mins, bins=500, density=True)\n",
        "    #normalized = hist/norm(hist)\n",
        "    #return normalized, bin_edges\n",
        "    return hist, bin_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT-kXdt-c_Di"
      },
      "source": [
        "def BoVW(data_train, data_test, test = False):\n",
        "    #number of clusters that are going to be created with kmeans clustering:\n",
        "    cluster_number =  [500,750,1000,1250,1500,1750,2000]\n",
        "    #percentage of initial descriptors to be implemented upon kmeans:\n",
        "    percentage = 0.5\n",
        "    #concatenation of training data:\n",
        "    vectors = np.concatenate(data_train)\n",
        "\n",
        "    N = vectors.shape[0]\n",
        "    #random subset of the initial vectors:\n",
        "    subsetOfvectors = []\n",
        "    for i in range(0, floor(percentage*N)):\n",
        "        temp = random.randint(0,N-1) \n",
        "        subsetOfvectors.append(vectors[temp])\n",
        "\n",
        "\n",
        "    if test:    \n",
        "        wcss = []\n",
        "        for i in cluster_number:\n",
        "            kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "            kmeans.fit(subsetOfvectors)\n",
        "            wcss.append(kmeans.inertia_)\n",
        "        plt.plot(cluster_number, wcss)\n",
        "        plt.title('Elbow Method')\n",
        "        plt.xlabel('Number of clusters')\n",
        "        plt.ylabel('WCSS')\n",
        "        plt.show()\n",
        "        return \n",
        "    \n",
        "    \n",
        "    kmeans = KMeans(n_clusters=500, init='k-means++', max_iter=50, n_init=10, random_state=0)\n",
        "    kmeans.fit(subsetOfvectors)\n",
        "    centers = kmeans.cluster_centers_\n",
        "#     plt.scatter(centers[:, 0], centers[:, 1])\n",
        "#     plt.show()\n",
        "\n",
        "   \n",
        "    BOF_tr = []\n",
        "    BOF_ts = []\n",
        "    for i in range(0,len(data_train)):\n",
        "        hist, bin_edges = BoVW_hist(data_train[i], centers, kmeans)\n",
        "#         if i<5:\n",
        "#             print(hist.shape)\n",
        "#             plt.hist(hist, bins=bin_edges)\n",
        "#             plt.show()\n",
        "        BOF_tr.append(hist)\n",
        "       \n",
        "    for i in range(0,len(data_test)):\n",
        "        hist, bin_edges = BoVW_hist(data_test[i], centers, kmeans)\n",
        "        BOF_ts.append(hist)\n",
        "        \n",
        "    return BOF_tr, BOF_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSlZFGRkdD9N"
      },
      "source": [
        "accs = []\n",
        "\"\"\"\n",
        "for k in range(5):\n",
        "    data_train, label_train, data_test, label_test = p3.createTrainTest(val1, k)\n",
        "    # Perform Kmeans to find centroids for clusters.\n",
        "    BOF_tr, BOF_ts = BoVW(data_train, data_test)\n",
        "    #centers = BoVW(data_train, data_test)\n",
        "    # Train an svm on the training set and make predictions on the test set\n",
        "    acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "    print(acc)\n",
        "    accs.append(acc)\n",
        "print(accs)\n",
        "\"\"\"\n",
        "data_train, label_train, data_test, label_test = p3.createTrainTest(val1, k)\n",
        "# Perform Kmeans to find centroids for clusters.\n",
        "BOF_tr, BOF_ts = BoVW(data_train, data_test)\n",
        "\n",
        "# Train an svm on the training set and make predictions on the test set\n",
        "acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
        "print(acc)\n",
        "accs.append(acc)\n",
        "print('Mean accuracy for Harris-Laplace with SURF descriptors: {:.3f}%'.format(100.0*np.mean(accs)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}